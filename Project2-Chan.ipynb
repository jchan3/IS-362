{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project 2 by Joe Chan\n",
    "====================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Code:\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "cm_df = pd.read_csv('Downloads/collegemajors.csv')\n",
    "ac_df = pd.read_csv('Downloads/accidents.csv')\n",
    "gu_df = pd.read_csv('Downloads/guns.csv')\n",
    "\n",
    "print (\"Here is a count of the NaN values in the college majors CSV: \")\n",
    "print (cm_df.isnull().sum())\n",
    "\n",
    "print (\"Here is a list of the top five unemployed majors: \")\n",
    "sort_unemployment = cm_df.sort_values('Unemployment_rate', ascending=False) \n",
    "print (sort_unemployment[['Major','Unemployment_rate']].head())\n",
    "\n",
    "print (\"Create a new column in the DataFrame for Percentage of Full-Time Employment by Major:\")\n",
    "cm_df['Full_Time_Percent'] = cm_df.apply(lambda r: r.Employed_full_time_year_round / r.Total, axis=1)\n",
    "new_cmdf = cm_df[['Major','Major_category','Total','Employed_full_time_year_round','Full_Time_Percent']].sort_values('Full_Time_Percent', ascending=False) \n",
    "print (new_cmdf.head())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "College Majors Employment CSV\n",
    "-----------------------------------------------\n",
    "The CSV was created from https://raw.githubusercontent.com/fivethirtyeight/data/master/college-majors/all-ages.csv\n",
    "\n",
    "The CSV file was uploaded from the location of Downloads/collegemajors.csv and read into the variable called \"cm_df\"\n",
    "\n",
    "The count of any Nan values in the DataFrame columns was displayed.\n",
    "\n",
    "A DataFrame of the top five unemployed majors by unemployment rate in descending order was created and displayed.\n",
    "\n",
    "The data in the cm_df datafile was transformed and made tidy to analyze the college major, employed, employed full time, unemployed, and unemployment rate.\n",
    "\n",
    "A new column was created called \"Full_Time_Percent\" which represented the percent of students with full time employment.\n",
    "\n",
    "This column was created by dividing the column \"Employed_full_time_year_round\" by \"Total\"\n",
    "\n",
    "The new DataFrame was created to include the new column and the DataFrame was sorted in descending order with the highest \"Full_Time_Percent\" college major listed first in the output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Code:\n",
    "```python\n",
    "ac_df = pd.read_csv('Downloads/accidents.csv')\n",
    "\n",
    "print (\"Here is a count of the NaN values in the Airline Accidents CSV: \")\n",
    "print (ac_df.isnull().sum())\n",
    "\n",
    "print (\"Create a new column for Total Incidents for each Airline:\")\n",
    "ac_df['Total_Incidents'] = ac_df.apply(lambda r: r.incidents_85_99 + r.incidents_00_14, axis=1)\n",
    "print (ac_df[['airline','Total_Incidents']].sort_values('Total_Incidents', ascending=False).head())\n",
    "\n",
    "print (\"Create a new column for Total Fatal Accidents for each Airline:\")\n",
    "ac_df['Total_Fatal_Accidents'] = ac_df.apply(lambda r: r.fatal_accidents_85_99 + r.fatal_accidents_00_14, axis=1)\n",
    "print (ac_df[['airline','Total_Fatal_Accidents']].sort_values('Total_Fatal_Accidents', ascending=False).head())\n",
    "\n",
    "print (\"Create a new column for Total Fatalities for each Airline:\")\n",
    "ac_df['Total_Fatalities'] = ac_df.apply(lambda r: r.fatalities_85_99 + r.fatalities_00_14, axis=1)\n",
    "print (ac_df[['airline','Total_Fatalities']].sort_values('Total_Fatalities', ascending=False).head())\n",
    "\n",
    "print (\"Create a new column for Total Percentage of Fatalities per available seats for each Airline.\")\n",
    "ac_df['Total_Percent_Fatalities'] = ac_df.apply(lambda r: r.Total_Fatalities / r.avail_seat_km_per_week, axis=1)\n",
    "\n",
    "print (\"Display the five airlines with the highest Total Percent Fatalities:\")\n",
    "new_acdf = ac_df[['airline','Total_Incidents','Total_Fatal_Accidents','Total_Fatalities','Total_Percent_Fatalities']].sort_values('Total_Percent_Fatalities', ascending=False) \n",
    "print (new_acdf.head())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Airline Fatal Accidents CSV\n",
    "---------------------------------------\n",
    "The CSV was created from https://raw.githubusercontent.com/fivethirtyeight/data/master/airline-safety/airline-safety.csv\n",
    "\n",
    "The CSV file was uploaded from the location of Downloads/accidents.csv and read into the variable called \"ac_df\"\n",
    "\n",
    "The count of any Nan values in the DataFrame columns was displayed.\n",
    "\n",
    "The data in the ac_df datafile was transformed and made tidy to analyze the airlines and the total fatalities.\n",
    "\n",
    "A new column was created called \"Total_Incidents\" which represented the total of the columns \"incidents_85_99\" and \"incidents_00_14\"\n",
    "\n",
    "A DataFrame of the top five Total_Incidents by airlines in descending order was displayed.\n",
    "\n",
    "A new column was created called \"Total_Fatal_Accidents\" which represented the total of the columns \"fatal_accidents_85_99\" and \"fatal_accidents_00_14\"\n",
    "\n",
    "A DataFrame of the top five Total_Fatal_Accidents by airlines in descending order was displayed.\n",
    "\n",
    "A new column was created called \"Total_Fatalities\" which represented the total of the columns \"fatalities_85_99\" and \"fatalities_00_14\"\n",
    "\n",
    "A DataFrame of the top five Total_Fatalities by airlines in descending order was displayed.\n",
    "\n",
    "A new column was created called \"Total_Percent_Fatalities\" which represented the newly created column \"Total_Fatalities\" divided by \"avail_seat_km_per_week\"\n",
    "\n",
    "The new DataFrame was created to include the 4 new columns and the DataFrame was sorted in descending order with the highest \"Total_Percent_Fatalities\" airlines listed first in the output.\n",
    "\n",
    "The five airlines with the highest \"Total_Percent_Fatalities\" for available seats was displayed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Code:\n",
    "```python\n",
    "gu_df = pd.read_csv('Downloads/guns.csv')\n",
    "\n",
    "print (\"Here is a count of the NaN values in the Gun Background Check CSV: \")\n",
    "print (gu_df.isnull().sum())\n",
    "\n",
    "print (\"Create a new DataFrame for Gun Background Check by State and Month using Pivot:\")\n",
    "new_gudf = gu_df.pivot(index='month',columns='state',values='totals')\n",
    "print (new_gudf.head())\n",
    "\n",
    "print (\"Find the Sum and Mean of Background Checks for New York, California, Texas, and Florida:\")\n",
    "CA_guns = new_gudf['California'].sum()\n",
    "CA_guns_avg = new_gudf['California'].mean()\n",
    "print (\"The total number of Background Checks in California is: \", CA_guns)\n",
    "print (\"The average number of Background Checks in California per month is: \", CA_guns_avg)\n",
    "\n",
    "NY_guns = new_gudf['New York'].sum()\n",
    "NY_guns_avg = new_gudf['New York'].mean()\n",
    "print (\"The total number of Background Checks in New York is: \", NY_guns)\n",
    "print (\"The average number of Background Checks in New York per month is: \", NY_guns_avg)\n",
    "\n",
    "TX_guns = new_gudf['Texas'].sum()\n",
    "TX_guns_avg = new_gudf['Texas'].mean()\n",
    "print (\"The total number of Background Checks in Texas is: \", TX_guns)\n",
    "print (\"The average number of Background Checks in Texas per month is: \", TX_guns_avg)\n",
    "\n",
    "FL_guns = new_gudf['Florida'].sum()\n",
    "FL_guns_avg = new_gudf['Florida'].mean()\n",
    "print (\"The total number of Background Checks in Florida is: \", FL_guns)\n",
    "print (\"The average number of Background Checks in Florida per month is: \", FL_guns_avg)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gun Background Checks CSV\n",
    "-----------------------------------------------\n",
    "CSV was created from https://raw.githubusercontent.com/BuzzFeedNews/nics-firearm-background-checks/master/data/nics-firearm-background-checks.csv\n",
    "\n",
    "The CSV file was uploaded from the location of Downloads/guns.csv and read into the variable called \"gu_df\"\n",
    "\n",
    "The count of any Nan values in the DataFrame columns was displayed.\n",
    "\n",
    "The data in the gu_df datafile was transformed and made tidy to analyze the Gun Background Check totals in the four most populous states of New York, Florida, Texas, and California.\n",
    "\n",
    "A new DataFrame called \"new_gudf\" was created to analyze the Gun Background Check by State and Month using the Pivot function.\n",
    "\n",
    "The pivot function used the 'month for index, the 'state' for columns, and the 'totals' for values.\n",
    "\n",
    "The new DataFrame listed all 50 states but only the sum and averages of the four states was analyzed using the mean and sum functions.\n",
    "\n",
    "The sum and average Gun Background Checks were displayed for New York, Florida, Texas, and California."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a count of the NaN values in the college majors CSV: \n",
      "Major_code                       0\n",
      "Major                            0\n",
      "Major_category                   0\n",
      "Total                            0\n",
      "Employed                         0\n",
      "Employed_full_time_year_round    0\n",
      "Unemployed                       0\n",
      "Unemployment_rate                0\n",
      "Median                           0\n",
      "P25th                            0\n",
      "P75th                            0\n",
      "dtype: int64\n",
      "Here is a list of the top five unemployed majors: \n",
      "                         Major  Unemployment_rate\n",
      "146    MISCELLANEOUS FINE ARTS           0.156147\n",
      "116        CLINICAL PSYCHOLOGY           0.102712\n",
      "93       MILITARY TECHNOLOGIES           0.101796\n",
      "27   SCHOOL STUDENT COUNSELING           0.101746\n",
      "77             LIBRARY SCIENCE           0.094843\n",
      "Create a new column in the DataFrame for Percentage of Full-Time Employment by Major:\n",
      "                                             Major           Major_category  \\\n",
      "169  MANAGEMENT INFORMATION SYSTEMS AND STATISTICS                 Business   \n",
      "18                COMPUTER AND INFORMATION SYSTEMS  Computers & Mathematics   \n",
      "21                            INFORMATION SCIENCES  Computers & Mathematics   \n",
      "65     MECHANICAL ENGINEERING RELATED TECHNOLOGIES              Engineering   \n",
      "47                            COMPUTER ENGINEERING              Engineering   \n",
      "\n",
      "      Total  Employed_full_time_year_round  Full_Time_Percent  \n",
      "169  156673                         118249           0.754750  \n",
      "18   253782                         189950           0.748477  \n",
      "21    77805                          57604           0.740364  \n",
      "65    29348                          21273           0.724853  \n",
      "47   154160                         111025           0.720193  \n",
      "Here is a count of the NaN values in the Airline Accidents CSV: \n",
      "airline                   0\n",
      "avail_seat_km_per_week    0\n",
      "incidents_85_99           0\n",
      "fatal_accidents_85_99     0\n",
      "fatalities_85_99          0\n",
      "incidents_00_14           0\n",
      "fatal_accidents_00_14     0\n",
      "fatalities_00_14          0\n",
      "dtype: int64\n",
      "Create a new column for Total Incidents for each Airline:\n",
      "                  airline  Total_Incidents\n",
      "1               Aeroflot*               82\n",
      "19     Delta / Northwest*               48\n",
      "11              American*               38\n",
      "51  United / Continental*               33\n",
      "22     Ethiopian Airlines               30\n",
      "Create a new column for Total Fatal Accidents for each Airline:\n",
      "                       airline  Total_Fatal_Accidents\n",
      "1                    Aeroflot*                     15\n",
      "19          Delta / Northwest*                     14\n",
      "51       United / Continental*                     10\n",
      "52  US Airways / America West*                      9\n",
      "11                   American*                      8\n",
      "Create a new column for Total Fatalities for each Airline:\n",
      "              airline  Total_Fatalities\n",
      "16     China Airlines               760\n",
      "34  Malaysia Airlines               571\n",
      "28     Japan Airlines               520\n",
      "11          American*               517\n",
      "6          Air India*               487\n",
      "Create a new column for Total Percentage of Fatalities per available seats for each Airline.\n",
      "Display the five airlines with the highest Total Percent Fatalities:\n",
      "                   airline  Total_Incidents  Total_Fatal_Accidents  \\\n",
      "29           Kenya Airways                4                      2   \n",
      "16          China Airlines               14                      7   \n",
      "13                 Avianca                5                      3   \n",
      "35  Pakistan International               18                      5   \n",
      "6               Air India*                6                      2   \n",
      "\n",
      "    Total_Fatalities  Total_Percent_Fatalities  \n",
      "29               283              1.020133e-06  \n",
      "16               760              9.345605e-07  \n",
      "13               323              8.137607e-07  \n",
      "35               280              8.032978e-07  \n",
      "6                487              5.602508e-07  \n",
      "Here is a count of the NaN values in the Gun Background Check CSV: \n",
      "month                            0\n",
      "state                            0\n",
      "permit                          24\n",
      "permit_recheck               11385\n",
      "handgun                         20\n",
      "long_gun                        19\n",
      "other                         6985\n",
      "multiple                         0\n",
      "admin                           23\n",
      "prepawn_handgun               1943\n",
      "prepawn_long_gun              1945\n",
      "prepawn_other                 7370\n",
      "redemption_handgun            1940\n",
      "redemption_long_gun           1941\n",
      "redemption_other              7370\n",
      "returned_handgun             10285\n",
      "returned_long_gun            10340\n",
      "returned_other               10670\n",
      "rentals_handgun              11495\n",
      "rentals_long_gun             11660\n",
      "private_sale_handgun          9735\n",
      "private_sale_long_gun         9735\n",
      "private_sale_other            9735\n",
      "return_to_seller_handgun     10010\n",
      "return_to_seller_long_gun     9735\n",
      "return_to_seller_other       10230\n",
      "totals                           0\n",
      "dtype: int64\n",
      "Create a new DataFrame for Gun Background Check by State and Month using Pivot:\n",
      "state    Alabama  Alaska  Arizona  Arkansas  California  Colorado  \\\n",
      "month                                                               \n",
      "1998-11     1062     145      379       589        2101       622   \n",
      "1998-12    35506    3840    17074     21163       65344     23176   \n",
      "1999-01    18049    2278    12859     11953       56953     19503   \n",
      "1999-02    20583    2413    14546     15348       57471     22239   \n",
      "1999-03    19424    3206    14992     13720       68327     17287   \n",
      "\n",
      "state    Connecticut  Delaware  District of Columbia  Florida   ...     \\\n",
      "month                                                           ...      \n",
      "1998-11           80        55                     0      812   ...      \n",
      "1998-12         6790      2080                     0    31529   ...      \n",
      "1999-01         6265      1128                     1    18999   ...      \n",
      "1999-02         8069      1077                     3    22252   ...      \n",
      "1999-03         7877      1314                     2    23492   ...      \n",
      "\n",
      "state    Tennessee  Texas   Utah  Vermont  Virgin Islands  Virginia  \\\n",
      "month                                                                 \n",
      "1998-11        107   2794    267       59               0        24   \n",
      "1998-12      24666  79605  10415     2057               0     25170   \n",
      "1999-01      18473  50992   5055     1043               0     14009   \n",
      "1999-02      23304  55148   5933     1668               0     16053   \n",
      "1999-03      23035  54096   6021     1941               0     17193   \n",
      "\n",
      "state    Washington  West Virginia  Wisconsin  Wyoming  \n",
      "month                                                   \n",
      "1998-11         361            408        241      107  \n",
      "1998-12       11641          13786      15201     3379  \n",
      "1999-01        8695           8260       7780     2180  \n",
      "1999-02        9383          11206      10578     2643  \n",
      "1999-03       10551          10867      14891     2776  \n",
      "\n",
      "[5 rows x 55 columns]\n",
      "Find the Sum and Mean of Background Checks for New York, California, Texas, and Florida:\n",
      "The total number of Background Checks in California is:  20395757\n",
      "The average number of Background Checks in California per month is:  85337.89539748954\n",
      "The total number of Background Checks in New York is:  5006146\n",
      "The average number of Background Checks in New York per month is:  20946.21757322176\n",
      "The total number of Background Checks in Texas is:  21061868\n",
      "The average number of Background Checks in Texas per month is:  88124.97071129706\n",
      "The total number of Background Checks in Florida is:  12953684\n",
      "The average number of Background Checks in Florida per month is:  54199.51464435147\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "cm_df = pd.read_csv('Downloads/collegemajors.csv')\n",
    "ac_df = pd.read_csv('Downloads/accidents.csv')\n",
    "gu_df = pd.read_csv('Downloads/guns.csv')\n",
    "\n",
    "print (\"Here is a count of the NaN values in the college majors CSV: \")\n",
    "print (cm_df.isnull().sum())\n",
    "\n",
    "print (\"Here is a list of the top five unemployed majors: \")\n",
    "sort_unemployment = cm_df.sort_values('Unemployment_rate', ascending=False) \n",
    "print (sort_unemployment[['Major','Unemployment_rate']].head())\n",
    "\n",
    "print (\"Create a new column in the DataFrame for Percentage of Full-Time Employment by Major:\")\n",
    "cm_df['Full_Time_Percent'] = cm_df.apply(lambda r: r.Employed_full_time_year_round / r.Total, axis=1)\n",
    "new_cmdf = cm_df[['Major','Major_category','Total','Employed_full_time_year_round','Full_Time_Percent']].sort_values('Full_Time_Percent', ascending=False) \n",
    "print (new_cmdf.head())\n",
    "\n",
    "\n",
    "print (\"Here is a count of the NaN values in the Airline Accidents CSV: \")\n",
    "print (ac_df.isnull().sum())\n",
    "\n",
    "print (\"Create a new column for Total Incidents for each Airline:\")\n",
    "ac_df['Total_Incidents'] = ac_df.apply(lambda r: r.incidents_85_99 + r.incidents_00_14, axis=1)\n",
    "print (ac_df[['airline','Total_Incidents']].sort_values('Total_Incidents', ascending=False).head())\n",
    "\n",
    "print (\"Create a new column for Total Fatal Accidents for each Airline:\")\n",
    "ac_df['Total_Fatal_Accidents'] = ac_df.apply(lambda r: r.fatal_accidents_85_99 + r.fatal_accidents_00_14, axis=1)\n",
    "print (ac_df[['airline','Total_Fatal_Accidents']].sort_values('Total_Fatal_Accidents', ascending=False).head())\n",
    "\n",
    "print (\"Create a new column for Total Fatalities for each Airline:\")\n",
    "ac_df['Total_Fatalities'] = ac_df.apply(lambda r: r.fatalities_85_99 + r.fatalities_00_14, axis=1)\n",
    "print (ac_df[['airline','Total_Fatalities']].sort_values('Total_Fatalities', ascending=False).head())\n",
    "\n",
    "print (\"Create a new column for Total Percentage of Fatalities per available seats for each Airline.\")\n",
    "ac_df['Total_Percent_Fatalities'] = ac_df.apply(lambda r: r.Total_Fatalities / r.avail_seat_km_per_week, axis=1)\n",
    "\n",
    "print (\"Display the five airlines with the highest Total Percent Fatalities:\")\n",
    "new_acdf = ac_df[['airline','Total_Incidents','Total_Fatal_Accidents','Total_Fatalities','Total_Percent_Fatalities']].sort_values('Total_Percent_Fatalities', ascending=False) \n",
    "print (new_acdf.head())\n",
    "\n",
    "\n",
    "print (\"Here is a count of the NaN values in the Gun Background Check CSV: \")\n",
    "print (gu_df.isnull().sum())\n",
    "\n",
    "print (\"Create a new DataFrame for Gun Background Check by State and Month using Pivot:\")\n",
    "new_gudf = gu_df.pivot(index='month',columns='state',values='totals')\n",
    "print (new_gudf.head())\n",
    "\n",
    "print (\"Find the Sum and Mean of Background Checks for New York, California, Texas, and Florida:\")\n",
    "CA_guns = new_gudf['California'].sum()\n",
    "CA_guns_avg = new_gudf['California'].mean()\n",
    "print (\"The total number of Background Checks in California is: \", CA_guns)\n",
    "print (\"The average number of Background Checks in California per month is: \", CA_guns_avg)\n",
    "\n",
    "NY_guns = new_gudf['New York'].sum()\n",
    "NY_guns_avg = new_gudf['New York'].mean()\n",
    "print (\"The total number of Background Checks in New York is: \", NY_guns)\n",
    "print (\"The average number of Background Checks in New York per month is: \", NY_guns_avg)\n",
    "\n",
    "TX_guns = new_gudf['Texas'].sum()\n",
    "TX_guns_avg = new_gudf['Texas'].mean()\n",
    "print (\"The total number of Background Checks in Texas is: \", TX_guns)\n",
    "print (\"The average number of Background Checks in Texas per month is: \", TX_guns_avg)\n",
    "\n",
    "FL_guns = new_gudf['Florida'].sum()\n",
    "FL_guns_avg = new_gudf['Florida'].mean()\n",
    "print (\"The total number of Background Checks in Florida is: \", FL_guns)\n",
    "print (\"The average number of Background Checks in Florida per month is: \", FL_guns_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
